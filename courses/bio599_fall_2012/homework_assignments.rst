==========================================================================================
Homework assignments
==========================================================================================

.. important:: I encourage you to discuss homework assignments with each other, but you may not view other student's assignments or share your assignment with others. When you start programming, you often think there is a single way to address a task, but that is usually not the case: there are many ways to complete these assignments, and when code has been shared or copied it is often very obvious to a more experienced eye.

Turning in your homework
------------------------
Your homework must always be turned in with a standardized name. That name should be ``<nau_id>_<homework_id>.<extension>``, where ``<nau_id>`` is your NAU identifier (for example, mine is ``jgc53``), and ``<homework_id>`` and ``<extension>`` are provided on a per-assignment basis. 

Unless otherwise noted, homework must be turned in by email to alk224@nau.edu before class on the day it is due. 

Accessing the cluster
---------------------
For the remaining assignments this semester we'll use an Amazon Cloud based cluster. You should have received a key file (``<nau-id>.rsa``) and ip address by email. (I won't post the ip address here for security reasons.) Use the key file and the ip address to connect as follows::

	ssh -i <key-file> <nau-id>@<ip-address>

For example, I would connect as follows::

	ssh -i jgc53.rsa jgc53@<ip-address>

Where ``<ip-address>`` is replaced with the IP address that was provided by email.

To move files in and out of the instance, I recommend using `Cyberduck <http://www.cyberduck.ch>`_. You can find `instructions for connecting to AWS with Cyberduck here <http://qiime.org/tutorials/working_with_aws.html#working-with-cyberduck>`_. Instead of the public DNS entry, you'll use the IP address referenced above. You can also experiment with `command line tools to move data in and out of the cluster <http://qiime.org/tutorials/working_with_aws.html#working-with-command-line-tools>`_. 

QIIME analysis (25 Oct 2012)
------------------------------

.. important:: This assignment involves large data files. You will need to work in your `scratch` directory, or you will run out of space. On logging into the cluster change to ``/mnt/<nau-id>`` where ``<nau-id>`` is your NAU identifier. For example, I would do this by running the command: ``cd /mnt/jgc53``.

.. important:: Remember that the ``screen`` command will be important to allow your analyses to continue running if your network connection is interrupted. You can find `details on screen here <http://www.ibm.com/developerworks/aix/library/au-gnu_screen/>`_.

Begin by reading `Fierer et al <http://www.pnas.org/content/107/14/6477.long>`_. You will use QIIME to recreate the analyses presented in this paper.

Data analysis: You will perform a complete QIIME analysis of the data set presented in Fierer et al, and turn in the following items:
 - evenly sampled OTU table (generated by `beta_diversity_through_3d_plots.py`)
 - PDF or PNG showing a single view of the unweighted unifrac 3d PCoA plot that you find informative (i.e., it should illustrate the conclusions presented in the Fierer et al paper)
 - text file containing the full list of commands that you ran to generate the above data, noting any problems that you ran into along the way

The following commands will get you started. Run these after logging in to your cluster account and changing into your `scratch` directory.
::
	
	# download the Fierer data
	wget https://s3.amazonaws.com/s3-public_ssu_data/fierer_forensic_keyboard.tgz
	
	# unpack the tgz file and change to the resulting directory
	tar -xvzf fierer_forensic_keyboard.tgz
	cd fierer_forensic_keyboard
	
	# unpack the sff file and the mapping file
	tar -xvzf study_232_FFCKVMW.sff.tgz
	unzip study_232_run_FFCKVMW_mapping.txt.zip
	
	# generate .fna and .qual files from the sff file
	process_sff.py -i ./

Hints:
 - From here you'll probably want to follow the steps in the `QIIME overview tutorial <http://qiime.org/svn_documentation/tutorials/tutorial.html>`_, but modified to use the data from the Fierer et al study. You may want to run that tutorial as-is first, to familiarize yourself with the steps.

.. important::
	Homework id: ``qiime``; Extension: ``biom``, ``png`` (or ``pdf``), and ``txt``; For this assignment, the files I turn in would be named <userid>_qiime_otu_table_even.biom, <userid>_qiime_unweighted_unifrac_pcoa.png (or <userid>_qiime_unweighted_unifrac_pcoa.pdf) and <userid>_qiime_analysis_notes.txt. 
	
	E-mail your files as attachments to alk224@nau.edu.


Shell script (due 9 Oct 2012)
------------------------------

In this assignment you will automate retrieval and processing of PDB files with a shell (``bash``) script, and turn that script in. We will run that script and grade you on the results. Your script should perform the following steps:

1. Create a new directory called ``<nau-id>_pdb_files`` (e.g., mine would be called ``jgc53_pdb_files``).

2. Create a file in that directory called ``pdb_retrieval.log`` which contains:
 a. the time the script began running (including descriptive text like `Logging started at:` ``<time>``) - this should only be the time, not the date (use google and ``man`` to figure out the formatting)
 b. the time the script completed running (again with descriptive text like `Logging ended at:` ``<time>``) - this should only be the time, not the date (use google and ``man`` to figure out the formatting) 
 c. the URLs of the files that were downloaded
 d. the date of the download (so in case of future changes to the files on the PDB you know what versions of the files you obtained) - this should only be the date, not the time (use google and ``man`` to figure out the formatting)
 e. any other information that you think might be important to log.

3. Download the following PDB records as PDB files in ``.gz`` format: ``4DA7``, ``1HSG``,  ``1ZQA``, ``2RNM``, ``1RCX``, ``1GFL``,  ``2WDK`` (Hint: first go to the Protein Data Bank website and find the link to those records. Then figure out how to generalize that link to match different records.)

4. Unzip all of the ``.gz`` files. (Hint: a wildcard expression is useful here.)

5. Extract the line(s) containing PMIDs (PubMed Identifiers) for each of the records (Hint: Use ``egrep`` for this, and review the files to figure out where that information is) and write those lines to a new file called ``pmids.txt``.

6. Extract the line(s) containing TITLE for each of the records (Hint: Use ``egrep`` for this, and review the files to figure out where that information is) and write those lines to a new file called ``titles.txt``. 

7. Zip all of the PDB files in the directory with ``gzip``.

.. important::
	Homework id: ``shellscript``; Extension: ``sh``; For this assignment, the script file I turn in would be named ``jgc53_shellscript.sh``. Note that you will not turn in any files in the ``pdb_files`` directory: we'll generate those using your script. 
	
	E-mail your shell script as an attachment to alk224@nau.edu.

Regular Expressions (due 18 Sept 2012)
--------------------------------------
Download the EMP minimal mapping file :download:`here <files/emp_11sept2012_minimal_mapping_file.txt.gz>` - you'll need to unzip that file to get started. You can read about the `file format here <http://qiime.org/documentation/file_formats.html#metadata-mapping-files>`_.

Perform the reformatting steps described below. You'll turn in two metadata mapping files, one for the human-associated samples and one for all other samples (this splitting is one of the formatting steps described below). You'll also turn in a *patterns file*, which will be a text file containing list of the search and replace patterns that were applied to perform the reformatting, including "comment" lines before each pair of patterns describing what the following pattern does. Comment lines *must* begin with the ``#`` symbol so they can be computationally differentiated from non-comment lines.

Each line in your *patterns file* should contain exactly one regular expression pattern: for each task you should have the search pattern on one line, followed by the replace pattern on the next line. These patterns must work in either TextWrangler or jEdit (I don't care which, but your patterns must work in one of the two).

The tasks you must achieve are as follows:

#. Replace all fields where full text is ``no_data`` with ``NA``

#. Reorder the columns so the final output is in this order: ``SampleID``, ``BarcodeSequence``, ``LinkerPrimerSequence``, ``LATITUDE``, ``LONGITUDE``, ``PRINCIPAL_INVESTIGATOR``, ``COUNTRY``, ``STUDY_ID``, [intermediate fields: order doesn't matter], ``Description``

#. Append ``emp.summer2012.`` to the beginning of each line except the header line.

#. Reformat ``RUN_DATE`` entries to contain full year (four digits rather than two)

#. Create two new fields from ``PCR_PRIMERS`` field: ``FWD_PCR_PRIMER`` and ``REV_PCR_PRIMER`` where each field contains the primer nucleotide sequence only (ie., including only the IUPAC nucleotide characters).

#. Remove these columns: ``EMP_PERSON``, ``PRINCIPAL_INVESTIGATOR_CONTACT``
	
#. Split the full metadata file into two subfiles: one for human-associated samples, and one for all other samples.

#. ``TAXONID`` and ``PMID`` refer to NCBI database entries. What do these mean? Thinking ahead, how might you automatically extract these the information that these terms refer to? Do some research... (NOTE: nothing to turn in for this one, but I will call on people in class to share their ideas.)

.. important::
	Homework id: ``regex``; Extension: ``txt``; For this assignment, the patterns file I turn in would be named ``jgc53_regex.txt``. The metadata mapping files should be named ``<nau_id>_human_emp_11sept2012_minimal_mapping_file.txt`` and ``<nau_id>_other_emp_11sept2012_minimal_mapping_file.txt`` where ``<nau_id>`` is your NAU identifier. Mine would be ``jgc53_human_emp_11sept2012_minimal_mapping_file.txt`` and ``jgc53_other_emp_11sept2012_minimal_mapping_file.txt``.
	
	E-mail these three files as attachments to alk224@nau.edu.


GC content (due 4 Sept 2012) 
----------------------------
Download a genome and compute its GC content (i.e., the percent of the genome that is composed of G or C). Turn in a max of one page describing the steps that you took to achieve this, including failed attempts, and the genome you selected (include a link to the download page) and the GC content that you computed.

Note that there are various ways that you can just look up the GC content, including via the IMG website. I'm asking you to compute it, and you're being graded on your description of the process. Getting the right answer is a bonus (i.e., if you spend a couple of hours trying, and get it wrong, you'll be graded on your well-documented effort, not your final answer).

Hints: Start with the IMG Genome Browser, and work with a bacterial, archaeal or viral genome.

Be creative - there are many ways to achieve this.

.. important::
	Homework id: ``gc_content``; Extension: ``pdf``; For this first assignment, the file I turn in would be named ``jgc53_gc_content.pdf``. 

Text editor (due 30 Aug 2012)
-----------------------------
Download and install a text editor. Use one of the ones recommended in PCFB. There is nothing to turn in for this assignment.
